{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafcfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit\\AppData\\Local\\Temp\\ipykernel_8632\\3415228297.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  players = pd.concat(players_all, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2644 unique players to: c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\players.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "RAW_TENNIS_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "\n",
    "OUTPUT_RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "OUTPUT_RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "wanted = [\n",
    "    \"player_id\", \"full_name\", \"name\", \"gender\", \"country\", \"height\",\n",
    "    \"current_rank\", \"slug\", \"birthplace\", \"plays\", \"current_prize\", \"total_prize\"\n",
    "]\n",
    "\n",
    "players_all = []\n",
    "\n",
    "for day in RAW_TENNIS_DIR.iterdir():\n",
    "    p = day / \"data\" / \"raw\" / \"raw_match_parquet\"\n",
    "    if not p.exists():\n",
    "        continue\n",
    "\n",
    "    for f in p.glob(\"*_team_*.parquet\"):\n",
    "        schema_cols = set(pq.read_schema(f).names)\n",
    "        cols = [c for c in wanted if c in schema_cols]\n",
    "\n",
    "        if not cols:  # Skip if no wanted columns exist in the file\n",
    "            continue\n",
    "\n",
    "        df = pd.read_parquet(f, columns=cols)\n",
    "\n",
    "        # If full_name is missing but \"name\" exists, use name as full_name\n",
    "        if \"full_name\" not in df.columns and \"name\" in df.columns:\n",
    "            df = df.rename(columns={\"name\": \"full_name\"})\n",
    "\n",
    "        players_all.append(df)\n",
    "\n",
    "players = pd.concat(players_all, ignore_index=True)\n",
    "\n",
    "# Keep the most complete record per player (based on non-null count)\n",
    "players[\"_nn\"] = players.notna().sum(axis=1)\n",
    "players_unique = (\n",
    "    players.sort_values(\"_nn\", ascending=False)\n",
    "           .drop_duplicates(subset=[\"player_id\"], keep=\"first\")\n",
    "           .drop(columns=[\"_nn\"])\n",
    ")\n",
    "\n",
    "output_path = OUTPUT_RAW_DIR / \"players.parquet\"\n",
    "players_unique.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {players_unique.shape[0]} unique players to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53723c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape: (2644, 12)\n",
      "Columns: ['player_id', 'full_name', 'name', 'gender', 'country', 'height', 'current_rank', 'slug', 'birthplace', 'plays', 'current_prize', 'total_prize']\n",
      "   player_id               full_name                name gender  \\\n",
      "0      88992       Muller, Alexandre           Muller A.      M   \n",
      "1     248846           Mayot, Harold            Mayot H.      M   \n",
      "2     192013  Auger-Aliassime, Felix  Auger-Aliassime F.      M   \n",
      "3     192862           Damas, Miguel            Damas M.      M   \n",
      "4     269291         Forejtek, Jonas         Forejtek J.      M   \n",
      "5     215205            Zhu, Michael              Zhu M.      M   \n",
      "6      77223         Martinez, Pedro         Martínez P.      M   \n",
      "7      63642   Kwiatkowski, Thai-Son      Kwiatkowski T.      M   \n",
      "8     460898        Bervid, Victoria           Bervid V.      F   \n",
      "9      52025             Wang, Yafan             Wang Y.      F   \n",
      "\n",
      "          country  height  current_rank                   slug  \\\n",
      "0          France    1.83          81.0       muller-alexandre   \n",
      "1          France    1.78         132.0           mayot-harold   \n",
      "2          Canada    1.93          30.0  auger-aliassime-felix   \n",
      "3           Spain    2.08         470.0           damas-miguel   \n",
      "4  Czech Republic    1.83         375.0         forejtek-jonas   \n",
      "5             USA    1.75         858.0            zhu-michael   \n",
      "6           Spain    1.85         101.0         martinez-pedro   \n",
      "7             USA    1.88         271.0   kwiatkowski-thai-son   \n",
      "8  Czech Republic    1.90         978.0        bervid-victoria   \n",
      "9           China    1.70          69.0             wang-yafan   \n",
      "\n",
      "               birthplace         plays  current_prize  total_prize  \n",
      "0          Poissy, France  right-handed       106522.0    1178035.0  \n",
      "1            Metz, France  right-handed        65798.0     424547.0  \n",
      "2        Montreal, Canada  right-handed       218538.0   10166964.0  \n",
      "3                  Madrid  right-handed         1183.0      40348.0  \n",
      "4                  Pilsen  right-handed         9321.0     137353.0  \n",
      "5            Princeton NJ  right-handed         1748.0      42605.0  \n",
      "6           Alzira, Spain  right-handed        39448.0    2732689.0  \n",
      "7      Charlotte, NC, USA  right-handed        18705.0     441448.0  \n",
      "8  Prague, Czech Republic  right-handed         1363.0       4948.0  \n",
      "9          Nanjing, China  right-handed       170316.0    2139419.0  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# مسیر از محل نوتبوک\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "# مسیر فایل پردازش‌شده\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "players_path = PROCESSED_DIR / \"players.parquet\"\n",
    "\n",
    "players = pd.read_parquet(players_path)\n",
    "\n",
    "print(\"DataFrame Shape:\", players.shape)\n",
    "print(\"Columns:\", players.columns.tolist())\n",
    "print(players.head(10))\n",
    "\n",
    "# To check columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb018a87",
   "metadata": {},
   "source": [
    "To create matches_event.parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940167c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of event files: 35053\n",
      "File created: c:\\Users\\mit\\Desktop\\Finaaal\\data\\raw\\matches_event.parquet\n",
      "Number of rows: 16873\n",
      "Columns: ['match_id', 'first_to_serve', 'home_team_seed', 'away_team_seed', 'custom_id', 'winner_code', 'default_period_count', 'start_datetime', 'match_slug', 'final_result_only']\n",
      "   match_id first_to_serve home_team_seed away_team_seed  custom_id  \\\n",
      "0  11974053           None           None           None    NNfsQTf   \n",
      "1  11974066           None           None           None    hTfsrpg   \n",
      "2  11998445              1           None              3  nPBbsdgpc   \n",
      "3  11998446              2           None           None   PfAsFyjc   \n",
      "4  11998447              1              4           None    FQAsyUF   \n",
      "\n",
      "  winner_code  default_period_count  start_datetime               match_slug  \\\n",
      "0           1                     3      1706878800  switzerland-netherlands   \n",
      "1           2                     3      1706871600              ukraine-usa   \n",
      "2           2                     3      1706810400   cazaux-auger-aliassime   \n",
      "3           2                     3      1706800800        cobolli-lestienne   \n",
      "4           1                     3      1706794200           martinez-coric   \n",
      "\n",
      "   final_result_only  \n",
      "0              False  \n",
      "1              False  \n",
      "2              False  \n",
      "3              False  \n",
      "4              False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "RAW_TENNIS_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "\n",
    "OUTPUT_RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "OUTPUT_RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "event_files = list(RAW_TENNIS_DIR.glob(\"**/data/raw/raw_match_parquet/event_*.parquet\"))\n",
    "print(\"Number of event files:\", len(event_files))\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for f in event_files:\n",
    "    try:\n",
    "        df = pd.read_parquet(f, engine=\"pyarrow\")\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "if dfs:\n",
    "    events_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Drop duplicates by match_id\n",
    "    if \"match_id\" in events_df.columns:\n",
    "        events_df = events_df.drop_duplicates(subset=[\"match_id\"])\n",
    "\n",
    "    out_file = OUTPUT_RAW_DIR / \"matches_event.parquet\"\n",
    "    events_df.to_parquet(out_file, engine=\"pyarrow\", index=False)\n",
    "\n",
    "    print(\"File created:\", out_file)\n",
    "    print(\"Number of rows:\", len(events_df))\n",
    "    print(\"Columns:\", list(events_df.columns))\n",
    "    print(events_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total players in original dataset: 2644\n",
      "Players with valid height (in meters): 1349\n",
      "Cleaned dataset saved to: c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\players_clean_heights.parquet\n",
      "Sample rows:\n",
      "   player_id               full_name                name gender  \\\n",
      "0      88992       Muller, Alexandre           Muller A.      M   \n",
      "1     248846           Mayot, Harold            Mayot H.      M   \n",
      "2     192013  Auger-Aliassime, Felix  Auger-Aliassime F.      M   \n",
      "3     192862           Damas, Miguel            Damas M.      M   \n",
      "4     269291         Forejtek, Jonas         Forejtek J.      M   \n",
      "5     215205            Zhu, Michael              Zhu M.      M   \n",
      "6      77223         Martinez, Pedro         Martínez P.      M   \n",
      "7      63642   Kwiatkowski, Thai-Son      Kwiatkowski T.      M   \n",
      "8     460898        Bervid, Victoria           Bervid V.      F   \n",
      "9      52025             Wang, Yafan             Wang Y.      F   \n",
      "\n",
      "          country  height  current_rank                   slug  \\\n",
      "0          France    1.83          81.0       muller-alexandre   \n",
      "1          France    1.78         132.0           mayot-harold   \n",
      "2          Canada    1.93          30.0  auger-aliassime-felix   \n",
      "3           Spain    2.08         470.0           damas-miguel   \n",
      "4  Czech Republic    1.83         375.0         forejtek-jonas   \n",
      "5             USA    1.75         858.0            zhu-michael   \n",
      "6           Spain    1.85         101.0         martinez-pedro   \n",
      "7             USA    1.88         271.0   kwiatkowski-thai-son   \n",
      "8  Czech Republic    1.90         978.0        bervid-victoria   \n",
      "9           China    1.70          69.0             wang-yafan   \n",
      "\n",
      "               birthplace         plays  current_prize  total_prize  \n",
      "0          Poissy, France  right-handed       106522.0    1178035.0  \n",
      "1            Metz, France  right-handed        65798.0     424547.0  \n",
      "2        Montreal, Canada  right-handed       218538.0   10166964.0  \n",
      "3                  Madrid  right-handed         1183.0      40348.0  \n",
      "4                  Pilsen  right-handed         9321.0     137353.0  \n",
      "5            Princeton NJ  right-handed         1748.0      42605.0  \n",
      "6           Alzira, Spain  right-handed        39448.0    2732689.0  \n",
      "7      Charlotte, NC, USA  right-handed        18705.0     441448.0  \n",
      "8  Prague, Czech Republic  right-handed         1363.0       4948.0  \n",
      "9          Nanjing, China  right-handed       170316.0    2139419.0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_parquet(DATA_RAW / \"players.parquet\").copy()\n",
    "\n",
    "# Ensure 'height' is numeric, convert invalid entries to NaN\n",
    "h = pd.to_numeric(df.get(\"height\"), errors=\"coerce\")\n",
    "\n",
    "# Normalize heights\n",
    "height_m = np.where(\n",
    "    (h > 1.3) & (h < 2.3),\n",
    "    h,\n",
    "    np.where(\n",
    "        (h >= 135) & (h <= 225),\n",
    "        h / 100.0,\n",
    "        np.nan\n",
    "    )\n",
    ")\n",
    "\n",
    "# Round and keep only heights in the plausible range (1.35m–2.25m) ===\n",
    "height_m = np.round(height_m, 2)\n",
    "valid_mask = (height_m >= 1.35) & (height_m <= 2.25)\n",
    "\n",
    "# Keep only valid rows and update 'height' column ===\n",
    "clean = df.loc[valid_mask].copy()\n",
    "clean[\"height\"] = height_m[valid_mask]\n",
    "\n",
    "# Drop 'height_clean' column if present\n",
    "if \"height_clean\" in clean.columns:\n",
    "    clean = clean.drop(columns=[\"height_clean\"])\n",
    "\n",
    "output_path = DATA_PROCESSED / \"players_clean_heights.parquet\"\n",
    "clean.to_parquet(output_path, index=False)\n",
    "\n",
    "print(\"Total players in original dataset:\", len(df))\n",
    "print(\"Players with valid height (in meters):\", len(clean))\n",
    "print(\"Cleaned dataset saved to:\", output_path)\n",
    "print(\"Sample rows:\")\n",
    "print(clean.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151422fa",
   "metadata": {},
   "source": [
    "Outliers Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0127e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of outliers outside [1.35, 2.25]: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# مسیرهای پروژه\n",
    "PROJECT_ROOT = Path.cwd().parent  # پوشه اصلی پروژه\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "players = pd.read_parquet(DATA_PROCESSED / \"players_clean_heights.parquet\")\n",
    "\n",
    "# بررسی داده‌های خارج از محدوده منطقی [1.35, 2.25] متر\n",
    "outliers = players[(players[\"height\"] < 1.35) | (players[\"height\"] > 2.25)]\n",
    "print(\"\\nNumber of outliers outside [1.35, 2.25]:\", len(outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9c46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values per column:\n",
      "player_id         0.00\n",
      "full_name         0.00\n",
      "name              0.00\n",
      "gender            0.07\n",
      "country           0.00\n",
      "height            0.00\n",
      "current_rank      0.67\n",
      "slug              0.00\n",
      "birthplace        0.44\n",
      "plays            28.17\n",
      "current_prize     0.59\n",
      "total_prize       0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# مسیر پروژه\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# بارگذاری فایل\n",
    "players = pd.read_parquet(DATA_PROCESSED / \"players_clean_heights.parquet\")\n",
    "\n",
    "# محاسبه درصد NaN برای هر ستون\n",
    "nan_percent = (players.isna().sum() / len(players) * 100).round(2)\n",
    "\n",
    "# نمایش نتیجه\n",
    "print(\"Percentage of NaN values per column:\")\n",
    "print(nan_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36271721",
   "metadata": {},
   "source": [
    "این کد داده‌های خام شلوغ و پراکنده از ۶۰ روز فولدر رو برمی‌داره، بازی‌ها رو پیدا می‌کنه، بازیکن‌های هر بازی رو با اطلاعات تورنومنت و برنده ترکیب می‌کنه، و یک فایل تمیز و یکتا تحویل می‌ده."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit\\AppData\\Local\\Temp\\ipykernel_8632\\1675896620.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(dfs, ignore_index=True)\n",
      "C:\\Users\\mit\\AppData\\Local\\Temp\\ipykernel_8632\\1675896620.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved c:\\Users\\mit\\Desktop\\Finaaal\\data\\raw\\match_results_player.parquet | rows: 57825\n",
      "   match_id  player_id            full_name  side    won  start_datetime  \\\n",
      "0  11998445   287803.0       Cazaux, Arthur  home  False      1706810400   \n",
      "1  11998446    62790.0  Lestienne, Constant  home  False      1706800800   \n",
      "2  11998447    64580.0         Ćorić, Borna  home  False      1706794200   \n",
      "3  11998448   131442.0        Mmoh, Michael  home  False      1706707800   \n",
      "4  11998449    22218.0        Paire, Benoit  home  False      1706725200   \n",
      "\n",
      "           name  winner_code  \n",
      "0     Cazaux A.          2.0  \n",
      "1  Lestienne C.          2.0  \n",
      "2      Ćorić B.          1.0  \n",
      "3       Mmoh M.          1.0  \n",
      "4      Paire B.          2.0  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "RAW_TENNIS_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_events():\n",
    "    raw_event_file = RAW_DIR / \"matches_event.parquet\"\n",
    "    desired_cols = [\"match_id\", \"start_datetime\", \"winner_code\", \"tournament_id\", \"tournament_name\"]\n",
    "\n",
    "    if raw_event_file.exists():\n",
    "        df = pd.read_parquet(raw_event_file)\n",
    "        return df[[c for c in desired_cols if c in df.columns]]\n",
    "\n",
    "    files = glob.glob(str(RAW_TENNIS_DIR / \"*\" / \"data\" / \"raw\" / \"raw_match_parquet\" / \"event_*.parquet\"))\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            dfs.append(pd.read_parquet(f, engine=\"pyarrow\"))\n",
    "        except Exception as e:\n",
    "            print(\"read error:\", f, e)\n",
    "    if not dfs:\n",
    "        raise SystemExit(\"No event files found.\")\n",
    "\n",
    "    evt = pd.concat(dfs, ignore_index=True)\n",
    "    keep = [c for c in desired_cols if c in evt.columns]\n",
    "    return evt[keep].drop_duplicates(subset=[\"match_id\"]) if \"match_id\" in evt.columns else evt.drop_duplicates()\n",
    "\n",
    "def load_team(side: str):\n",
    "    raw_team_file = RAW_DIR / f\"matches_{side}_team.parquet\"\n",
    "    pattern = f\"{side}_team*.parquet\"\n",
    "\n",
    "    if raw_team_file.exists():\n",
    "        return pd.read_parquet(raw_team_file)\n",
    "\n",
    "    files = glob.glob(str(RAW_TENNIS_DIR / \"*\" / \"data\" / \"raw\" / \"raw_match_parquet\" / pattern))\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            dfs.append(pd.read_parquet(f, engine=\"pyarrow\"))\n",
    "        except Exception as e:\n",
    "            print(\"read error:\", f, e)\n",
    "    if not dfs:\n",
    "        raise SystemExit(f\"No {side}_team files found.\")\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    if {\"match_id\", \"player_id\"}.issubset(df.columns):\n",
    "        df = df.drop_duplicates(subset=[\"match_id\", \"player_id\"])\n",
    "    else:\n",
    "        df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "events = load_events()\n",
    "home = load_team(\"home\")\n",
    "away = load_team(\"away\")\n",
    "\n",
    "def norm_team(df, side_label):\n",
    "    cols = [c for c in [\"match_id\", \"player_id\", \"full_name\", \"name\", \"team_name\"] if c in df.columns]\n",
    "    out = df[cols].copy()\n",
    "    if \"full_name\" not in out.columns and \"name\" in out.columns:\n",
    "        out = out.rename(columns={\"name\": \"full_name\"})\n",
    "    out[\"side\"] = side_label\n",
    "    return out\n",
    "\n",
    "home_n = norm_team(home, \"home\")\n",
    "away_n = norm_team(away, \"away\")\n",
    "\n",
    "# Combine players from both sides\n",
    "players_per_match = pd.concat([home_n, away_n], ignore_index=True)\n",
    "\n",
    "# Merge with event info\n",
    "res = players_per_match.merge(\n",
    "    events,\n",
    "    on=\"match_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\" if \"match_id\" in events.columns else \"many_to_many\"\n",
    ")\n",
    "\n",
    "# Mark winners where possible\n",
    "if \"winner_code\" in res.columns:\n",
    "    res[\"won\"] = (res[\"side\"] == res[\"winner_code\"]).where(res[\"winner_code\"].notna(), pd.NA)\n",
    "else:\n",
    "    res[\"won\"] = pd.NA\n",
    "\n",
    "priority = [\"match_id\", \"player_id\", \"full_name\", \"side\", \"won\", \"start_datetime\", \"tournament_id\", \"tournament_name\"]\n",
    "ordered_cols = [c for c in priority if c in res.columns] + [c for c in res.columns if c not in priority]\n",
    "res = res[ordered_cols]\n",
    "\n",
    "output_file = RAW_DIR / \"match_results_player.parquet\"\n",
    "res.to_parquet(output_file, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(f\"Saved {output_file} | rows: {len(res)}\")\n",
    "print(res.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ff13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics files found: 23291\n",
      "Saved merged statistics to: c:\\Users\\mit\\Desktop\\Finaaal\\data\\raw\\statistics_all.parquet | Rows: 1,358,234\n",
      "   match_id      statistic_name     home_stat    away_stat period\n",
      "0  11998445                aces            12            6    NaN\n",
      "1  11998445       double_faults             2            7    NaN\n",
      "2  11998445         first_serve  57/101 (56%)  53/90 (59%)    NaN\n",
      "3  11998445        second_serve   42/44 (95%)  30/37 (81%)    NaN\n",
      "4  11998445  first_serve_points   42/57 (74%)  39/53 (74%)    NaN\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "RAW_TENNIS_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "stats_all_file = RAW_DIR / \"statistics_all.parquet\"\n",
    "\n",
    "stat_files = glob.glob(\n",
    "    str(RAW_TENNIS_DIR / \"**\" / \"data\" / \"raw\" / \"raw_statistics_parquet\" / \"*.parquet\"),\n",
    "    recursive=True\n",
    ")\n",
    "print(f\"Statistics files found: {len(stat_files)}\")\n",
    "if not stat_files:\n",
    "    raise RuntimeError(\"No statistics files found.\")\n",
    "\n",
    "# Read and keep only important columns\n",
    "use_cols = [\"match_id\", \"period\", \"statistic_name\", \"home_stat\", \"away_stat\"]\n",
    "dfs = []\n",
    "for f in stat_files:\n",
    "    try:\n",
    "        df = pd.read_parquet(f, columns=[c for c in use_cols if c != \"period\"])\n",
    "        if \"period\" not in df.columns:\n",
    "            df[\"period\"] = pd.NA\n",
    "        dfs.append(df)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "stats_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "stats_all.to_parquet(stats_all_file, index=False)\n",
    "print(f\"Saved merged statistics to: {stats_all_file} | Rows: {len(stats_all):,}\")\n",
    "print(stats_all.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebf1d9",
   "metadata": {},
   "source": [
    "پر کردن وینر کد های خالی و ساخت یک  فایل پارکت جدید :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb393e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\match_results_player_filled.parquet\n",
      "Matches with total_won available: 11,209\n",
      "Newly filled winner_code (from statistics): 3,019\n",
      "Remaining NaN winner_code: 4,636\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "stats_all_file = PROJECT_ROOT / \"data\" / \"raw\" / \"statistics_all.parquet\"\n",
    "player_file = PROJECT_ROOT / \"data\" / \"raw\" / \"match_results_player.parquet\"\n",
    "out_file = PROJECT_ROOT / \"data\" / \"processed\" / \"match_results_player_filled.parquet\"\n",
    "\n",
    "stats = pd.read_parquet(stats_all_file)\n",
    "\n",
    "stats = stats[stats[\"statistic_name\"] == \"total_won\"].copy()\n",
    "\n",
    "stats[\"_period_rank\"] = np.where(stats[\"period\"].fillna(\"\") == \"ALL\", 0, 1)\n",
    "\n",
    "# Keep one row per match_id (best period first)\n",
    "stats = (\n",
    "    stats\n",
    "    .sort_values([\"_period_rank\"])\n",
    "    .drop_duplicates(subset=[\"match_id\"], keep=\"first\")\n",
    ")\n",
    "\n",
    "# Clean & determine winner_code from stats\n",
    "for c in [\"home_stat\", \"away_stat\"]:\n",
    "    stats[c] = pd.to_numeric(stats[c], errors=\"coerce\")\n",
    "\n",
    "stats[\"winner_from_stats\"] = np.where(\n",
    "    stats[\"home_stat\"] > stats[\"away_stat\"], 1,\n",
    "    np.where(stats[\"away_stat\"] > stats[\"home_stat\"], 2, np.nan)\n",
    ")\n",
    "\n",
    "winner_map = stats[[\"match_id\", \"winner_from_stats\", \"home_stat\", \"away_stat\"]].rename(\n",
    "    columns={\"home_stat\": \"total_won_home\", \"away_stat\": \"total_won_away\"}\n",
    ")\n",
    "\n",
    "# Load match_results_player.parquet and fill missing winner_code\n",
    "players = pd.read_parquet(player_file)\n",
    "\n",
    "before_null = players[\"winner_code\"].isna().sum() if \"winner_code\" in players.columns else len(players)\n",
    "if \"winner_code\" not in players.columns:\n",
    "    players[\"winner_code\"] = np.nan\n",
    "\n",
    "# Merge and fill\n",
    "merged = players.merge(winner_map, on=\"match_id\", how=\"left\")\n",
    "mask_fill = merged[\"winner_code\"].isna() & merged[\"winner_from_stats\"].notna()\n",
    "merged.loc[mask_fill, \"winner_code\"] = merged.loc[mask_fill, \"winner_from_stats\"]\n",
    "\n",
    "after_null = merged[\"winner_code\"].isna().sum()\n",
    "filled_rows = int(before_null - after_null)\n",
    "\n",
    "\n",
    "out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "merged.to_parquet(out_file, index=False)\n",
    "\n",
    "# Report\n",
    "print(f\"Saved: {out_file}\")\n",
    "print(f\"Matches with total_won available: {winner_map['match_id'].nunique():,}\")\n",
    "print(f\"Newly filled winner_code (from statistics): {filled_rows:,}\")\n",
    "print(f\"Remaining NaN winner_code: {after_null:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09aafae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit\\AppData\\Local\\Temp\\ipykernel_8632\\2118595866.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  home_all = pd.concat(home_dfs, ignore_index=True)\n",
      "C:\\Users\\mit\\AppData\\Local\\Temp\\ipykernel_8632\\2118595866.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  away_all = pd.concat(away_dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "TENIS_RAW = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "PLAYER_FILLED_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"match_results_player_filled.parquet\"\n",
    "\n",
    "df_filled = pd.read_parquet(PLAYER_FILLED_PATH)\n",
    "\n",
    "home_dfs = []\n",
    "away_dfs = []\n",
    "\n",
    "for date_dir in sorted(TENIS_RAW.iterdir()):\n",
    "    if date_dir.is_dir() and \"20240201\" <= date_dir.name <= \"20240331\":\n",
    "        raw_dir = date_dir / \"data\" / \"raw\" / \"raw_match_parquet\"\n",
    "        if raw_dir.exists():\n",
    "            for f in raw_dir.rglob(\"home_team_*.parquet\"):\n",
    "                df_home = pd.read_parquet(f).rename(columns={\n",
    "                    \"player_id\": \"home_player_id\",\n",
    "                    \"full_name\": \"home_full_name\"\n",
    "                })\n",
    "                home_dfs.append(df_home)\n",
    "            for f in raw_dir.rglob(\"away_team_*.parquet\"):\n",
    "                df_away = pd.read_parquet(f).rename(columns={\n",
    "                    \"player_id\": \"away_player_id\",\n",
    "                    \"full_name\": \"away_full_name\"\n",
    "                })\n",
    "                away_dfs.append(df_away)\n",
    "\n",
    "home_all = pd.concat(home_dfs, ignore_index=True)\n",
    "away_all = pd.concat(away_dfs, ignore_index=True)\n",
    "\n",
    "merged_home_away = pd.merge(home_all, away_all, on=\"match_id\", suffixes=(\"_home\", \"_away\"))\n",
    "df_updated = pd.merge(df_filled, merged_home_away, on=\"match_id\", how=\"left\")\n",
    "\n",
    "df_updated.to_parquet(PLAYER_FILLED_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c54dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 849506\n",
      "Unique match_id: 16873\n",
      "Matches without determined winner_name: 4478\n",
      "File saved to: c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\match_results_with_winner.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "INPUT_FILE = PROJECT_ROOT / \"data\" / \"processed\" / \"match_results_player_filled.parquet\"\n",
    "OUTPUT_FILE = PROJECT_ROOT / \"data\" / \"processed\" / \"match_results_with_winner.parquet\"\n",
    "\n",
    "df = pd.read_parquet(INPUT_FILE)\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Unique match_id: {df['match_id'].nunique()}\")\n",
    "\n",
    "df = df.drop_duplicates(subset=\"match_id\").copy()\n",
    "\n",
    "def get_winner(row):\n",
    "    if row[\"winner_code\"] == 1:\n",
    "        return row[\"name_home\"]\n",
    "    if row[\"winner_code\"] == 2:\n",
    "        return row[\"name_away\"]\n",
    "    if pd.notna(row.get(\"total_won_home\")) and pd.notna(row.get(\"total_won_away\")):\n",
    "        if row[\"total_won_home\"] > row[\"total_won_away\"]:\n",
    "            return row[\"name_home\"]\n",
    "        if row[\"total_won_home\"] < row[\"total_won_away\"]:\n",
    "            return row[\"name_away\"]\n",
    "    return None\n",
    "\n",
    "df[\"winner_name\"] = df.apply(get_winner, axis=1)\n",
    "\n",
    "print(f\"Matches without determined winner_name: {df['winner_name'].isna().sum()}\")\n",
    "\n",
    "df.to_parquet(OUTPUT_FILE, index=False)\n",
    "print(f\"File saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e75d48",
   "metadata": {},
   "source": [
    "بازیکن با بیشترین برد :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f53fbec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       winner_slug  win_count\n",
      "1685  popko-dmitry         32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"../data/processed/match_results_with_winner.parquet\")\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# ساخت ستون slug برنده بر اساس winner_code\n",
    "df[\"winner_slug\"] = df.apply(\n",
    "    lambda row: row[\"slug_home\"] if row[\"winner_code\"] == 1 else row[\"slug_away\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# پیدا کردن نفر اول با بیشترین برد\n",
    "top_winner_stats = (\n",
    "    df.groupby(\"winner_slug\")\n",
    "    .size()\n",
    "    .reset_index(name=\"win_count\")\n",
    "    .sort_values(\"win_count\", ascending=False)\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "print(top_winner_stats)\n",
    "\n",
    "# I used slug to count more accurately because it's unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cdfbfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan Count: 60\n",
      "Nan Percentage: 2.27%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# تعیین روت پروژه (یک سطح بالاتر از اسکریپت فعلی)\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# ساخت مسیر فایل players.parquet در مسیر raw\n",
    "file_path = project_root / \"data\" / \"raw\" / \"players.parquet\"\n",
    "\n",
    "# لود داده‌ها\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# تعداد کل ردیف‌ها\n",
    "total_rows = len(df)\n",
    "\n",
    "# تعداد و درصد مقادیر NaN در ستون current_rank\n",
    "nan_count = df[\"current_rank\"].isna().sum()\n",
    "nan_percent = (nan_count / total_rows) * 100\n",
    "\n",
    "print(f\"Nan Count: {nan_count}\")\n",
    "print(f\"Nan Percentage: {nan_percent:.2f}%\")\n",
    "\n",
    "# Nan % is low. It's ready to analyze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2583ef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    right-handed\n",
      "1    right-handed\n",
      "2    right-handed\n",
      "3    right-handed\n",
      "4    right-handed\n",
      "5    right-handed\n",
      "6    right-handed\n",
      "7    right-handed\n",
      "8    right-handed\n",
      "9    right-handed\n",
      "Name: plays, dtype: object\n",
      "\n",
      "Percentage of NaN in 'plays': 56.66%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. تعیین روت پروژه (یک سطح بالاتر از محل اجرای اسکریپت)\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# 2. ساخت مسیر فایل players.parquet\n",
    "file_path = project_root / \"data\" / \"raw\" / \"players.parquet\"\n",
    "\n",
    "# 3. بارگذاری دیتاست\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# 4. نمایش اولین 49 مقدار ستون 'plays'\n",
    "print(df[\"plays\"].head(10))\n",
    "\n",
    "# 5. محاسبه درصد NaN در ستون 'plays'\n",
    "nan_percentage = df[\"plays\"].isna().mean() * 100\n",
    "print(f\"\\nPercentage of NaN in 'plays': {nan_percentage:.2f}%\")\n",
    "\n",
    "# Displays the first 49 values of the 'plays' column\n",
    "# from players.parquet and prints the percentage of missing (NaN) values in that column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93121053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australia', 'Austria']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. تعیین مسیر روت پروژه (یک سطح بالاتر از پوشه اسکریپت جاری)\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# 2. مسیر کامل به فایل players.parquet در data/raw\n",
    "players_file = project_root / \"data\" / \"raw\" / \"players.parquet\"\n",
    "\n",
    "# 3. بارگذاری داده‌ها\n",
    "players = pd.read_parquet(players_file)\n",
    "\n",
    "# 4. لیست یکتا و تمیز از کشورها\n",
    "countries = sorted(players[\"country\"].dropna().str.strip().unique())\n",
    "\n",
    "# 5. پیدا کردن نام‌های مشابه\n",
    "checked = set()\n",
    "for country in countries:\n",
    "    if country not in checked:\n",
    "        matches = get_close_matches(country, countries, n=5, cutoff=0.85)\n",
    "        if len(matches) > 1:\n",
    "            print(matches)\n",
    "        checked.update(matches)\n",
    "\n",
    "        # Checks for duplicated or misspelled country names by\n",
    "        # finding similar names with a high match ratio.\n",
    "        # In this dataset countries are cleaned. (Australia and Austria are not the same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6726a8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 57825\n",
      "Missing winner_code: 7655\n",
      "Percent missing: 13.24%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. تعیین مسیر روت پروژه\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# 2. مسیر کامل به فایل\n",
    "match_file = project_root / \"data\" / \"raw\" / \"match_results_player.parquet\"\n",
    "\n",
    "# 3. بارگذاری داده‌ها\n",
    "df = pd.read_parquet(match_file)\n",
    "\n",
    "# 4. محاسبه مجموع ردیف‌ها و درصد winner_codeهای خالی\n",
    "total = len(df)\n",
    "missing = df[\"winner_code\"].isna().sum()\n",
    "percent = (missing / total) * 100\n",
    "\n",
    "# 5. چاپ نتایج\n",
    "print(f\"Total rows: {total}\")\n",
    "print(f\"Missing winner_code: {missing}\")\n",
    "print(f\"Percent missing: {percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca4caea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\tournaments_all_2024.parquet\n",
      "   match_id  tournament_id      tournament_name     tournament_slug\n",
      "0  11974053          70826           Qualifiers          qualifiers\n",
      "1  11974066          70826           Qualifiers          qualifiers\n",
      "2  11998445         126168  Montpellier, France  montpellier-france\n",
      "3  11998446         126168  Montpellier, France  montpellier-france\n",
      "4  11998447         126168  Montpellier, France  montpellier-france\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "TENIS_RAW = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_tournaments = []\n",
    "\n",
    "# Loop through dated folders like 2024****\n",
    "for date_dir in TENIS_RAW.glob(\"2024*\"):\n",
    "    if date_dir.is_dir() and re.match(r\"2024\\d{4}\", date_dir.name):\n",
    "        raw_match_path = date_dir / \"data\" / \"raw\" / \"raw_match_parquet\"\n",
    "        if raw_match_path.exists():\n",
    "            for file in raw_match_path.glob(\"tournament_*.parquet\"):\n",
    "                try:\n",
    "                    df = pd.read_parquet(file)\n",
    "                    needed_cols = [\n",
    "                        \"match_id\", \"tournament_id\",\n",
    "                        \"tournament_name\", \"tournament_slug\", \"start_datetime\"\n",
    "                    ]\n",
    "                    available_cols = [c for c in needed_cols if c in df.columns]\n",
    "                    if available_cols:\n",
    "                        all_tournaments.append(df[available_cols])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Combine and save\n",
    "if all_tournaments:\n",
    "    tournaments_df = (\n",
    "        pd.concat(all_tournaments, ignore_index=True)\n",
    "          .drop_duplicates()\n",
    "    )\n",
    "    output_file = PROC_DIR / \"tournaments_all_2024.parquet\"\n",
    "    tournaments_df.to_parquet(output_file, index=False)\n",
    "    print(f\"Saved: {output_file}\")\n",
    "    print(tournaments_df.head())\n",
    "else:\n",
    "    print(\"No tournament files found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150eee5",
   "metadata": {},
   "source": [
    "برای سوال نهم اطلاعات مربوط به راند بازی هارو به دو بخش فوریه و مارس تقسیم کردم : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2886fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4274 rows to c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\match_round_info_february.parquet\n",
      "Saved 5159 rows to c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\match_round_info_march.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "TENIS_RAW = PROJECT_ROOT / \"data\" / \"raw\" / \"tennis_data\"\n",
    "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Month ranges\n",
    "feb_dirs = [d for d in TENIS_RAW.glob(\"202402*\") if d.is_dir()]\n",
    "mar_dirs = [d for d in TENIS_RAW.glob(\"202403*\") if d.is_dir()]\n",
    "\n",
    "def process_month(dirs, save_name):\n",
    "    dfs = []\n",
    "    for date_dir in dirs:\n",
    "        parquet_dir = date_dir / \"data\" / \"raw\" / \"raw_match_parquet\"\n",
    "        if parquet_dir.exists():\n",
    "            for file in parquet_dir.glob(\"round_*.parquet\"):\n",
    "                try:\n",
    "                    df = pd.read_parquet(file)\n",
    "                    required = [\"match_id\", \"round_id\", \"slug\", \"cup_round_type\"]\n",
    "                    if set(required).issubset(df.columns):\n",
    "                        dfs.append(df[required])\n",
    "                    else:\n",
    "                        print(f\"Skipped (missing cols): {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file}: {e}\")\n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "        save_path = PROC_DIR / save_name\n",
    "        combined_df.to_parquet(save_path, index=False)\n",
    "        print(f\"Saved {len(combined_df)} rows to {save_path}\")\n",
    "    else:\n",
    "        print(f\"No valid round parquet files found for {save_name}\")\n",
    "\n",
    "# Feb & Mar 2024\n",
    "process_month(feb_dirs, \"match_round_info_february.parquet\")\n",
    "process_month(mar_dirs, \"match_round_info_march.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "February cup_round_type values:\n",
      "cup_round_type\n",
      "1.0      101\n",
      "2.0      210\n",
      "4.0      505\n",
      "8.0     1100\n",
      "16.0    1861\n",
      "NaN      497\n",
      "Name: count, dtype: int64\n",
      "NaN percentage: 11.63% (497/4274)\n",
      "\n",
      "March cup_round_type values:\n",
      "cup_round_type\n",
      "1.0      159\n",
      "2.0      340\n",
      "4.0      624\n",
      "8.0     1112\n",
      "16.0    2025\n",
      "NaN      899\n",
      "Name: count, dtype: int64\n",
      "NaN percentage: 17.43% (899/5159)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROC_DIR = Path(\"../data/processed\")\n",
    "\n",
    "def show_cup_round_counts(filename, label):\n",
    "    file_path = PROC_DIR / filename\n",
    "    if file_path.exists():\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        print(f\"\\n{label} cup_round_type values:\")\n",
    "        print(df[\"cup_round_type\"].value_counts(dropna=False).sort_index())\n",
    "\n",
    "        # Calculate NaN percentage\n",
    "        total_rows = len(df)\n",
    "        nan_count = df[\"cup_round_type\"].isna().sum()\n",
    "        nan_percentage = (nan_count / total_rows) * 100\n",
    "        print(f\"NaN percentage: {nan_percentage:.2f}% ({nan_count}/{total_rows})\")\n",
    "\n",
    "\n",
    "show_cup_round_counts(\"match_round_info_february.parquet\", \"February\")\n",
    "show_cup_round_counts(\"match_round_info_march.parquet\", \"March\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c3a39",
   "metadata": {},
   "source": [
    "To add ground_type to my tournament file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54750880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before merge: (16873, 4)\n",
      "Found 35671 tournament_*.parquet files\n",
      "After merge: (16873, 5)\n",
      "   match_id  tournament_id      tournament_name     tournament_slug  \\\n",
      "0  11974053          70826           Qualifiers          qualifiers   \n",
      "1  11974066          70826           Qualifiers          qualifiers   \n",
      "2  11998445         126168  Montpellier, France  montpellier-france   \n",
      "3  11998446         126168  Montpellier, France  montpellier-france   \n",
      "4  11998447         126168  Montpellier, France  montpellier-france   \n",
      "\n",
      "        ground_type  \n",
      "0              None  \n",
      "1              None  \n",
      "2  Hardcourt indoor  \n",
      "3  Hardcourt indoor  \n",
      "4  Hardcourt indoor  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "raw_dir = project_root / \"data\" / \"raw\" / \"tennis_data\"\n",
    "processed_dir = project_root / \"data\" / \"processed\"\n",
    "tourn_path = processed_dir / \"tournaments_all_2024.parquet\"\n",
    "\n",
    "df_tourn = pd.read_parquet(tourn_path)\n",
    "print(\"Before merge:\", df_tourn.shape)\n",
    "\n",
    "files = list(raw_dir.glob(\"2024*/data/raw/raw_match_parquet/tournament_*.parquet\"))\n",
    "print(f\"Found {len(files)} tournament_*.parquet files\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        df_tmp = pd.read_parquet(f, columns=[\"match_id\", \"ground_type\"])\n",
    "        dfs.append(df_tmp)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "if dfs:\n",
    "    df_ground = pd.concat(dfs, ignore_index=True).drop_duplicates(subset=[\"match_id\"])\n",
    "\n",
    "    df_merged = df_tourn.merge(df_ground, on=\"match_id\", how=\"left\")\n",
    "\n",
    "    df_merged.to_parquet(tourn_path, index=False)\n",
    "    print(\"After merge:\", df_merged.shape)\n",
    "    print(df_merged.head())\n",
    "else:\n",
    "    print(\"No tournament_*.parquet files with 'ground_type' found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f03256",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf05e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35671 time_*.parquet files\n",
      "Shape: (35671, 6)\n",
      "   match_id period_1 period_2 period_3 period_4 period_5\n",
      "0  11974053     None     None     None     None     None\n",
      "1  11974066     None     None     None     None     None\n",
      "2  11998445     3259     2639     4202     None     None\n",
      "3  11998446     2488     2375     None     None     None\n",
      "4  11998447     3741     1913     None     None     None\n",
      "Saved to c:\\Users\\mit\\Desktop\\Finaaal\\data\\processed\\all_match_periods.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "raw_dir = project_root / \"data\" / \"raw\" / \"tennis_data\"\n",
    "\n",
    "# پیدا کردن تمام فایل های time_*.parquet\n",
    "files = list(raw_dir.glob(\"2024*/data/raw/raw_match_parquet/time_*.parquet\"))\n",
    "print(f\"Found {len(files)} time_*.parquet files\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        df_tmp = pd.read_parquet(f)\n",
    "        # فقط ستون های match_id و period_* رو برمی‌داریم\n",
    "        period_cols = [c for c in df_tmp.columns if c.startswith(\"period_\")]\n",
    "        keep_cols = [\"match_id\"] + period_cols\n",
    "        df_tmp = df_tmp[keep_cols]\n",
    "        dfs.append(df_tmp)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "df_periods = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Shape:\", df_periods.shape)\n",
    "print(df_periods.head())\n",
    "\n",
    "out_dir = project_root / \"data\" / \"processed\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "df_periods.to_parquet(out_dir / \"all_match_periods.parquet\", index=False)\n",
    "print(f\"Saved to {out_dir / 'all_match_periods.parquet'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf37e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
